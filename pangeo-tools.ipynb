{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"_static/small_e_logo_cropped.png\" width=\"40%\" /></div>\n",
    "<div style=\"text-align:center\"><img src=\"_static/pangeo_simple_logo.png\" width=\"175px\" /></div>\n",
    "</center>\n",
    "\n",
    "Pangeo Tools\n",
    "===========\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A brief overview of the ecosystem of tools used by the [Pangeo Project](http://pangeo.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", )\n",
    "np.set_printoptions(precision=4, threshold=5)\n",
    "xr.set_options(display_width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pangeo is:\n",
    "\n",
    "- a community promoting open, reproducible, and scalable science.\n",
    "- an integrated ecosystem of open source software tools.\n",
    "- a community platform for Big Data Geoscience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Where to find Pangeo:\n",
    "\n",
    "- Online: http://pangeo.io/\n",
    "- GitHub: https://github.com/pangeo-data/\n",
    "- Discourse: https://discourse.pangeo.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"text-align:center\"><img src=\"_static/scientific_python_eco.png\" width=\"100%\" /></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Basics\n",
    "\n",
    "NumPy / SciPy / Pandas/ Jupyter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### NumPy\n",
    "\n",
    "NumPy is the fundamental package for scientific computing with Python. It contains among other things:\n",
    "\n",
    "- a powerful N-dimensional array object\n",
    "- sophisticated (broadcasting) functions\n",
    "- tools for integrating C/C++ and Fortran code\n",
    "- useful linear algebra, Fourier transform, and random number capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.ones((4, 2))\n",
    "x.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SciPy\n",
    "\n",
    "SciPy is a collection of mathematical algorithms and convenience functions built on the NumPy extension of Python. It contains subpackages that cover:\n",
    "\n",
    "- clustering\n",
    "- FFTs\n",
    "- interpolation\n",
    "- linear algebra\n",
    "- singal processing\n",
    "- stats\n",
    "- optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "x, y = np.mgrid[0:5, 2:8]\n",
    "tree = spatial.KDTree(list(zip(x.ravel(), y.ravel())))\n",
    "pts = np.array([[0, 0], [2.1, 2.9]])\n",
    "tree.query(pts)\n",
    "\n",
    "tree.query(pts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pandas\n",
    "\n",
    "Pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. Pandas is well suited for:\n",
    "\n",
    "- Tabular data types (see `Series` and `DataFrame` objects)\n",
    "- Timeseries data manipulation like resampling\n",
    "- Database-like operations like aligning, merging, joining, reshaping, and grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/chico_temperature.csv', index_col=0, parse_dates=True)\n",
    "display(df.head())\n",
    "df.resample('AS').max().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Jupyter\n",
    "\n",
    "TODO:\n",
    "\n",
    "- JupyterHub\n",
    "- Jupyterlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Xarray\n",
    "\n",
    "<!-- <div style=\"text-align:center\"><img src=\"_static/dataset-diagram.png\" width=\"50%\" /></div> -->\n",
    "<img src=\"_static/dataset-diagram.png\" align=\"right\" width=66% alt=\"Xarray Dataset\">\n",
    "\n",
    "\n",
    "Xarray is a Python library that provides data structures and tools for working with multidimensional labeled datasets and arrays. Xarray enables users to perform operations on complex datasets making it a powerful high-level tool for data analysis. \n",
    "\n",
    "- Inspired by Pandas and NetCDF\n",
    "- Labeled N-Dimensional data structures (`DataArray` and `Dataset`)\n",
    "- Toolkit for data manipulation and visualization\n",
    "- Integrates with scientific Python ecosystem (Pandas/Matplotlib/Dask/etc)\n",
    "- Backend support for a wide range of ND data formats (NetCDF, GRIB, Raster, Zarr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### xarray.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "ds = xr.tutorial.load_dataset('air_temperature')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### xarray.DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "da = ds['air']\n",
    "\n",
    "da.isel(time=0, lat=5, lon=10)  # select using integer index\n",
    "da.sel(time='2013-01-01T18:00:00', lat=62.5, lon=225.0)  # select based on label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# resample data to monthly means\n",
    "da_month = da.resample(time='MS').mean('time')\n",
    "\n",
    "da_climo = da_month.groupby('time.month').mean('time')\n",
    "da_climo\n",
    "# remove the monthly climotology\n",
    "da_no_climo = da_month.groupby('time.month') - da_climo\n",
    "da_no_climo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# integrated plotting\n",
    "da_climo.plot(col='month', col_wrap=6, robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dask\n",
    "\n",
    "<img src=\"https://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\" align=\"right\" width=50% alt=\"Dask Logo\">\n",
    "\n",
    "Dask is a flexible parallel computing library for analytic computing. Dask provides dynamic parallel task scheduling and high-level big-data collections like dask.array and dask.dataframe.\n",
    "\n",
    "- Dask Array implements a subset of the NumPy ndarray interface using blocked algorithms, cutting up the large array into many small arrays.\n",
    "- Tools like Xarray and Iris use Dask arrays under-the-hood\n",
    "- Dask can be deployed on a local computer, HPC, or the Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dask Arrays\n",
    "\n",
    "A dask array looks and feels a lot like a numpy array. However, a dask array doesn't directly hold any data. Instead, it symbolically represents the computations needed to generate the data. Nothing is actually computed until the actual numerical values are needed. This mode of operation is called \"lazy\"; it allows one to build up complex, large calculations symbolically before turning them over the scheduler for execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Numpy\n",
    "import numpy as np\n",
    "shape = (1000, 4000)\n",
    "ones_np = np.ones(shape)\n",
    "ones_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Dask\n",
    "import dask.array as da\n",
    "chunk_shape = (1000, 1000)\n",
    "ones = da.ones(shape, chunks=chunk_shape)\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deploying Dask\n",
    "\n",
    "The Dask Schedulers orchestrate the tasks in the Task Graphs so that they can be run in parallel. How they run in parallel, though, is determined by which Scheduler you choose.\n",
    "\n",
    "There are 3 *local* schedulers:\n",
    "\n",
    "- **Single-Thread Local**: For debugging, profiling, and diagnosing issues\n",
    "- **Multi-threaded**: Using the Python built-in threading package (the default for all Dask operations except Bags)\n",
    "- **Multi-process**: Using the Python built-in multiprocessing package (the default for Dask Bags)\n",
    "\n",
    "and 1 distributed scheduler, which we will talk about later:\n",
    "\n",
    "- **Distributed**: Using the dask.distributed module (which uses tornado for TCP communication). The distributed scheduler uses a Cluster to manage communication between the scheduler and the \"workers\". This is described in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Distributed Clusters (http://distributed.dask.org/)¶\n",
    "Dask can be deployed on distributed infrastructure, such as a an HPC system or a cloud computing system.\n",
    "\n",
    "- LocalCluster - Creates a Cluster that can be executed locally. Each Cluster includes a Scheduler and Workers.\n",
    "- Client - Connects to and drives computation on a distributed Cluster\n",
    "\n",
    "**Dask Jobqueue (http://jobqueue.dask.org/)**\n",
    "- PBSCluster\n",
    "- SlurmCluster\n",
    "- etc.\n",
    "\n",
    "**Dask Kubernetes (http://kubernetes.dask.org/)**\n",
    "- KubeCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "# On Cheyenne:\n",
    "from dask_jobqueue import PBSCluster\n",
    "cluster = PBSCluster(project=...)\n",
    "\n",
    "# On Caseper\n",
    "from dask_jobqueue import SlurmCluster\n",
    "cluster = SlurmCluster(project=...)\n",
    "\n",
    "# On the cloud\n",
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster()\n",
    "\n",
    "# use adaptive scaling!\n",
    "cluster.adapt(0, 30)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualization\n",
    "\n",
    "Python a rich ecosystem of data visualization tools.\n",
    "\n",
    "- Matplotlib:\n",
    "- Holoviz (Bokeh, Hvplot, Datashader, Panel):\n",
    "- Cartopy:\n",
    "\n",
    "More coming here soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
