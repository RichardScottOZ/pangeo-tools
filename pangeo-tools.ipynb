{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"_static/small_e_logo_cropped.png\" width=\"40%\" /></div>\n",
    "<div style=\"text-align:center\"><img src=\"_static/pangeo_simple_logo.png\" width=\"175px\" /></div>\n",
    "</center>\n",
    "\n",
    "Pangeo Tools\n",
    "===========\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A brief overview of the ecosystem of tools used by the [Pangeo Project](http://pangeo.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", )\n",
    "np.set_printoptions(precision=4, threshold=5)\n",
    "xr.set_options(display_width=80)\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pangeo is:\n",
    "\n",
    "- a community promoting open, reproducible, and scalable science.\n",
    "- an integrated ecosystem of open source software tools.\n",
    "- a community platform for Big Data Geoscience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Where to find Pangeo:\n",
    "\n",
    "- Online: http://pangeo.io/\n",
    "- GitHub: https://github.com/pangeo-data/\n",
    "- Discourse: https://discourse.pangeo.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"text-align:center\"><img src=\"_static/scientific_python_eco.png\" width=\"100%\" /></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Basics\n",
    "\n",
    "NumPy / SciPy / Pandas/ Jupyter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### NumPy\n",
    "\n",
    "NumPy is the fundamental package for scientific computing with Python. It contains among other things:\n",
    "\n",
    "- a powerful N-dimensional array object\n",
    "- sophisticated (broadcasting) functions\n",
    "- tools for integrating C/C++ and Fortran code\n",
    "- useful linear algebra, Fourier transform, and random number capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.ones((4, 2))\n",
    "x.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SciPy\n",
    "\n",
    "SciPy is a collection of mathematical algorithms and convenience functions built on the NumPy extension of Python. It contains subpackages that cover:\n",
    "\n",
    "- clustering\n",
    "- FFTs\n",
    "- interpolation\n",
    "- linear algebra\n",
    "- singal processing\n",
    "- stats\n",
    "- optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "x, y = np.mgrid[0:5, 2:8]\n",
    "tree = spatial.KDTree(list(zip(x.ravel(), y.ravel())))\n",
    "pts = np.array([[0, 0], [2.1, 2.9]])\n",
    "tree.query(pts)\n",
    "\n",
    "tree.query(pts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pandas\n",
    "\n",
    "Pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with “relational” or “labeled” data both easy and intuitive. Pandas is well suited for:\n",
    "\n",
    "- Tabular data types (see `Series` and `DataFrame` objects)\n",
    "- Timeseries data manipulation like resampling\n",
    "- Database-like operations like aligning, merging, joining, reshaping, and grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/chico_temperature.csv', index_col=0, parse_dates=True)\n",
    "display(df.head())\n",
    "df.resample('AS').max().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Jupyter\n",
    "\n",
    "TODO:\n",
    "\n",
    "- JupyterHub\n",
    "- Jupyterlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Legacy Climate Science Tools\n",
    "\n",
    "![legacy tools](_static/legacy_tools.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Legacy Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Pros\n",
    "\n",
    "- \"Metadata aware\" -- understand the relationships between variables, coordinates, etc.\n",
    "- \"Lazy evaluation\" -- don't perform computations until results are actually needed\n",
    "- Built-in visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Cons\n",
    "\n",
    "- Hard to scale up, don't handle big data well\n",
    "- Hard to hack / extend / modify\n",
    "- Isolated from broader software ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "_Can we have the best of both worlds?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Xarray\n",
    "\n",
    "<!-- <div style=\"text-align:center\"><img src=\"_static/dataset-diagram.png\" width=\"50%\" /></div> -->\n",
    "<img src=\"_static/dataset-diagram.png\" align=\"right\" width=66% alt=\"Xarray Dataset\">\n",
    "\n",
    "\n",
    "Xarray is a Python library that provides data structures and tools for working with multidimensional labeled datasets and arrays. Xarray enables users to perform operations on complex datasets making it a powerful high-level tool for data analysis. \n",
    "\n",
    "- Inspired by Pandas and NetCDF\n",
    "- Labeled N-Dimensional data structures (`DataArray` and `Dataset`)\n",
    "- Toolkit for data manipulation and visualization\n",
    "- Integrates with scientific Python ecosystem (Pandas/Matplotlib/Dask/etc)\n",
    "- Backend support for a wide range of ND data formats (NetCDF, GRIB, Raster, Zarr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### xarray.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "ds = xr.tutorial.load_dataset('air_temperature')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### xarray.DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "da = ds['air']\n",
    "\n",
    "da.isel(time=0, lat=5, lon=10)  # select using integer index\n",
    "da.sel(time='2013-01-01T18:00:00', lat=62.5, lon=225.0)  # select based on label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# resample data to monthly means\n",
    "da_month = da.resample(time='MS').mean('time')\n",
    "\n",
    "da_climo = da_month.groupby('time.month').mean('time')\n",
    "da_climo\n",
    "# remove the monthly climotology\n",
    "da_no_climo = da_month.groupby('time.month') - da_climo\n",
    "da_no_climo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# integrated plotting\n",
    "da_climo.plot(col='month', col_wrap=6, robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dask\n",
    "\n",
    "<img src=\"https://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\" align=\"right\" width=50% alt=\"Dask Logo\">\n",
    "\n",
    "Dask is a flexible parallel computing library for analytic computing. Dask provides dynamic parallel task scheduling and high-level big-data collections like dask.array and dask.dataframe.\n",
    "\n",
    "- Dask Array implements a subset of the NumPy ndarray interface using blocked algorithms, cutting up the large array into many small arrays.\n",
    "- Tools like Xarray and Iris use Dask arrays under-the-hood\n",
    "- Dask can be deployed on a local computer, HPC, or the Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dask Arrays\n",
    "\n",
    "A dask array looks and feels a lot like a numpy array. However, a dask array doesn't directly hold any data. Instead, it symbolically represents the computations needed to generate the data. Nothing is actually computed until the actual numerical values are needed. This mode of operation is called \"lazy\"; it allows one to build up complex, large calculations symbolically before turning them over the scheduler for execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Numpy\n",
    "import numpy as np\n",
    "shape = (1000, 4000)\n",
    "ones_np = np.ones(shape)\n",
    "ones_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Dask\n",
    "import dask.array as da\n",
    "chunk_shape = (1000, 1000)\n",
    "ones = da.ones(shape, chunks=chunk_shape)\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deploying Dask\n",
    "\n",
    "The Dask Schedulers orchestrate the tasks in the Task Graphs so that they can be run in parallel. How they run in parallel, though, is determined by which Scheduler you choose.\n",
    "\n",
    "There are 3 *local* schedulers:\n",
    "\n",
    "- **Single-Thread Local**: For debugging, profiling, and diagnosing issues\n",
    "- **Multi-threaded**: Using the Python built-in threading package (the default for all Dask operations except Bags)\n",
    "- **Multi-process**: Using the Python built-in multiprocessing package (the default for Dask Bags)\n",
    "\n",
    "and 1 distributed scheduler, which we will talk about later:\n",
    "\n",
    "- **Distributed**: Using the dask.distributed module (which uses tornado for TCP communication). The distributed scheduler uses a Cluster to manage communication between the scheduler and the \"workers\". This is described in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Distributed Clusters (http://distributed.dask.org/)¶\n",
    "Dask can be deployed on distributed infrastructure, such as a an HPC system or a cloud computing system.\n",
    "\n",
    "- LocalCluster - Creates a Cluster that can be executed locally. Each Cluster includes a Scheduler and Workers.\n",
    "- Client - Connects to and drives computation on a distributed Cluster\n",
    "\n",
    "**Dask Jobqueue (http://jobqueue.dask.org/)**\n",
    "- PBSCluster\n",
    "- SlurmCluster\n",
    "- etc.\n",
    "\n",
    "**Dask Kubernetes (http://kubernetes.dask.org/)**\n",
    "- KubeCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "# On Cheyenne:\n",
    "from dask_jobqueue import PBSCluster\n",
    "cluster = PBSCluster(project=...)\n",
    "\n",
    "# On Caseper\n",
    "from dask_jobqueue import SlurmCluster\n",
    "cluster = SlurmCluster(project=...)\n",
    "\n",
    "# On the cloud\n",
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster()\n",
    "\n",
    "# use adaptive scaling!\n",
    "cluster.adapt(0, 30)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualization\n",
    "\n",
    "Python a rich ecosystem of data visualization tools.\n",
    "\n",
    "- Matplotlib:\n",
    "- Holoviz (Bokeh, Hvplot, Datashader, Panel):\n",
    "- Cartopy:\n",
    "\n",
    "More coming here soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Climate-Specific Packages\n",
    "\n",
    "Everything we just showed was very general purpose.\n",
    "\n",
    "Now a brief tour of some more specialized tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Principles for Pangeo Packages\n",
    "\n",
    "- Consume and produce xarray data structures (don't do I/O)\n",
    "- Operate eagerly on NumPy inputs and lazily on Dask inputs \n",
    "- Follow existing metadata standards (e.g. CF convetions)\n",
    "- Keep it as simple as possible! Solve one problem well\n",
    "\n",
    "This favors many small, specialized packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## xESMF: Universal Regridder for Geospatial Data\n",
    "\n",
    "<https://xesmf.readthedocs.io/en/latest/>\n",
    "\n",
    "- **Powerful**: It uses ESMF/ESMPy as backend and can regrid between general curvilinear grids with all ESMF regridding algorithms, such as bilinear, conservative and nearest neighbour.\n",
    "- **Easy-to-use**: It abstracts away ESMF’s complicated infrastructure and provides a simple, high-level API, compatible with xarray as well as basic numpy arrays.\n",
    "- **Fast**: It is faster than ESMPy’s original Fortran regridding engine in serial case, and also supports dask for out-of-core, parallel computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Curvilinear Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.tutorial.load_dataset('rasm')\n",
    "plt.figure(figsize=(12, 4))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ds.Tair[0].plot(x='xc', y='yc', ax=ax, add_colorbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Output Grid\n",
    "\n",
    "A regular, coarse resolution lat-lon grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xesmf\n",
    "ds_out = xesmf.util.grid_global(5, 4)\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dsr = ds.rename({'xc': 'lon', 'yc': 'lat'})\n",
    "regridder = xesmf.Regridder(dsr, ds_out, 'bilinear')\n",
    "ds_out = regridder(dsr.Tair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Cell above dies on my macbook with error\n",
    "\n",
    "    Fatal error in MPI_Init_thread: Other MPI error, error stack:\n",
    "    MPIR_Init_thread(572)..............: \n",
    "    MPID_Init(224).....................: channel initialization failed\n",
    "    MPIDI_CH3_Init(105)................: \n",
    "    MPID_nem_init(324).................: \n",
    "    MPID_nem_tcp_init(178).............: \n",
    "    MPID_nem_tcp_get_business_card(425): \n",
    "    MPID_nem_tcp_init(384).............: gethostbyname failed, Ryans-MacBook-Pro.local (errno 1)\n",
    "    [unset]: write_line error; fd=-1 buf=:cmd=abort exitcode=3191567\n",
    "    :\n",
    "\n",
    "https://github.com/JiaweiZhuang/xESMF/issues/68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## climpred: analysis of ensemble forecast models for climate prediction\n",
    "\n",
    "<https://climpred.readthedocs.io/en/stable/>\n",
    "\n",
    "> climpred aims to be the primary package used to analyze output from initialized dynamical forecast models, ranging from short-term weather forecasts to decadal climate forecasts. The code base will be driven entirely by the geoscientific prediction community through open source development. It leverages xarray to keep track of core prediction ensemble dimensions (e.g., ensemble member, initialization date, and lead time) and dask to perform out-of-memory computations on large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EOFS: EOF analysis of spatial-temporal data\n",
    "\n",
    "<https://ajdawson.github.io/eofs/latest/>\n",
    "\n",
    "- Suitable for large data sets: computationally efficient for the large output data sets of modern climate models.\n",
    "- Transparent handling of missing values: missing values are removed automatically during computations and placed back into output fields.\n",
    "- Automatic metadata: metadata from input fields is used to construct metadata for output fields.\n",
    "- No Compiler required: a fast implementation written in pure Python using the power of numpy, no Fortran or C dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from eofs.xarray import Eof\n",
    "solver = Eof(sst_anom_detrended, weights=np.sqrt(weights))\n",
    "eof1 = solver.eofsAsCorrelation(neofs=1)\n",
    "pc1 = solver.pcs(npcs=1, pcscaling=1)\n",
    "eof1.sel(mode=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![eofs result](_static/eofs_output.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
